{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "moderate-sarah",
   "metadata": {},
   "source": [
    "# Introduction to Apache Arrow\n",
    "\n",
    "In this lab, we will briefly introduce the Apache Arrow columnar in-memory format and the associated Python library `pyarrow`.\n",
    "\n",
    "The learning objectives of this lab are as follows. You will:\n",
    "\n",
    "- Learn about the in-memory layout of high-level languages and their run-time platforms, such that you become aware of its limitations for big data analytics applications.\n",
    "- Learn about the columnar in-memory layout of Apache Arrow, such that you understand how it can help to perform better for many big data analytics use-cases.\n",
    "- Learn to use `pyarrow` to store tabular data structures in a columnar fashion, such that many typical operations are executed more efficiently.\n",
    "\n",
    "*Technical disclaimer: this lab assumes you are using the CPython implementation of Python. If you don't know what this means, you are very likely using CPython. Sometimes when design decision of Python are discussed, they may actually refer to the CPython implementation of the Python language, but for the sake of keeping the material concise, we will pretend to ignore the difference.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "patient-activation",
   "metadata": {},
   "source": [
    "## 1: A data-centric view of Python\n",
    "\n",
    "When you're using software languages with a high level of abstraction, chances are you don't have to think much about how the data objects you are working with are stored in memory.\n",
    "Typically, the in-memory layout of data in high-level languages and the virtual machines or interpreters that they run on can be quite different from what you may have seen in languages such as C, C++ or Rust.\n",
    "\n",
    "Let's first look at a typical way to store a sequence of integers in a computer memory.\n",
    "Suppose we want to store the following sequence $S$ of integers in a memory: \n",
    "$$\n",
    "S = \\{0, 3, 3, -7\\}\n",
    "$$\n",
    "\n",
    "Most CPUs are designed to store (and operate on) such integers in their two's complement form.\n",
    "CPUs have arithmetic units that operate on such integers with a pre-defined number of bits.\n",
    "This is usually some power of two number of bits starting from eight, since memories are almost always addressed per byte (eight bits).\n",
    "For example, if we choose to store the integers of this sequence in a byte-addressable memory starting at address zero, using 16-bits, we end up with:\n",
    "\n",
    "| Sequence index | Value | Size (bytes) | Address | Value (binary) |\n",
    "|----------------|-------|--------------|---------|----------------|\n",
    "|              0 |     0 |            2 |       0 |       00000000 |\n",
    "|                |       |              |       1 |       00000000 |\n",
    "|              1 |     3 |            2 |       2 |       00000011 |\n",
    "|                |       |              |       3 |       00000000 |\n",
    "|              2 |     3 |            2 |       4 |       00000011 |\n",
    "|                |       |              |       5 |       00000000 |\n",
    "|              3 |    -7 |            2 |       6 |       11111001 |\n",
    "|                |       |              |       7 |       11111111 |\n",
    "\n",
    "**<center>Table 1: Example of how the C language typically stores sequence S in memory.</center>**\n",
    "\n",
    "Note that we've stored the integers in a *little-endian* manner (we store the least-significant byte of the integer at the lowest address).\n",
    "Indeed, this is how a \"low-level language\" like C would store this sequence of 16-bit integers on a little-endian machines such as `x86`, `arm` or `ppc64le` (`le` stands for little-endian, since `ppc64` is originally big-endian).\n",
    "\n",
    "Let's take a look at how a high-level language like Python does this in the next example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ranging-january",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We first define a few utility function that help us print the size and address of a Python object.\n",
    "import sys\n",
    "\n",
    "\n",
    "def addr(obj):\n",
    "    \"\"\"Returns the Python ID of an object, which for CPython is its start address in memory. \"\"\"\n",
    "    return id(obj)\n",
    "\n",
    "\n",
    "def sizeof(obj):\n",
    "    \"\"\"Returns the size of a Python object in bytes.\"\"\"\n",
    "    return sys.getsizeof(obj)\n",
    "\n",
    "\n",
    "# We typically use a Python list to store a sequence of integers, as follows:\n",
    "S = [0, 3, 3, -7]\n",
    "\n",
    "# In Python, everything is an object.\n",
    "# S is an object, and the integers that S holds are also objects.\n",
    "# Let's take a closer look:\n",
    "\n",
    "print(\"The sequence S is at address {} and has a size of {} bytes.\".format(addr(S), sizeof(S)))\n",
    "\n",
    "fmt = \"{:>5}, {:>5}, {:>12}, {:>13}, {:>14}\"\n",
    "print(fmt.format(\"Index\", \"Value\", \"Size (bytes)\", \"Type\", \"Address\"))\n",
    "for i, n in enumerate(S):\n",
    "    print(fmt.format(i, n, sizeof(n), str(type(n)), addr(n)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "composed-hostel",
   "metadata": {},
   "source": [
    "The previous cell should output something like ...\n",
    "\n",
    "```\n",
    "The sequence S is at address 140600455194240 and has a size of 120 bytes.\n",
    "Index, Value, Size (bytes),          Type,        Address\n",
    "    0,     0,           24, <class 'int'>, 140600553568528\n",
    "    1,     3,           28, <class 'int'>, 140600553568624\n",
    "    2,     3,           28, <class 'int'>, 140600553568624\n",
    "    3,    -7,           28, <class 'int'>, 140600455489552\n",
    "```\n",
    "**<center>Output 1: Output of inspecting a Python list with integers.</center>**\n",
    "\n",
    "... (although the addresses will be different every time you reset the Notebook).\n",
    "\n",
    "When we compare Output 1 to the Table 1, a few things are important to notice:\n",
    "\n",
    "1. The type of each integer is a ***class*** `int` - everything is an object in Python.\n",
    "2. The size of each integer varies, compared to 2 bytes for each integer in C. Python integers are larger because every Python object has a header that is used for e.g. memory management. Also, the Python `int` object has a variable size, that generally increases when the value it represents increases.\n",
    "3. At indices 1 and 2, where the values are equal, the addresses are the same. The Python interpreter tries to prevent copies of the same data wherever possible. Since the values at these indices are the same, they point to the same object in memory.\n",
    "\n",
    "We also see the list object `S` being at a much different address than the list values. A Python list object in memory actually holds the list size and a pointer to an array of pointers to the values (those brave enough can check out [the CPython source code for the list object]).\n",
    "If you add some numbers to the sequence in the code above, you will see that the size of the list object `S` will not even change; only the internally stored list size and the array of pointers are updated.\n",
    "Because of the approach Python has taken, there are two levels of indirection to get from the list object to one of its actual values!\n",
    "The object `S`, its internal array, and the values of `S` may be stored all over the memory.\n",
    "So, consecutive sequence values may not be stored in contiguously addresses in the memory.\n",
    "\n",
    "##### The takeaway is ...\n",
    "... that when you're using a high-level language like Python, R, or even Java, the in-memory format of your data may be much different than you expect!**\n",
    "When you're writing a script to automate some boring tasks, this is usually not really a problem.\n",
    "However, when you have to do high-performance computing or big data analytics, you are likely to run into performance issues quickly with Python (or R, or even Java), if you don't do something about it.\n",
    "\n",
    "[the CPython source code for the list object]: https://github.com/python/cpython/blob/main/Include/cpython/listobject.h"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incoming-presence",
   "metadata": {},
   "source": [
    "## 2: Apache Arrow\n",
    "\n",
    "Based on the previous section, you may think Python is not so good, because it uses more space and more indirections (pointers) in the memory to store our data. Traversing our data structure, e.g. iterating over the list, may take longer than for other languages.\n",
    "However, keep in mind what Python was designed for: portability, programmer productivity, and readibility for scripts that automate everyday tasks, but not necessarily to push a CPU to its limit in doing useful work.\n",
    "Because Python is so [productive] and readible, it became very popular; so popular that people even want to use it for high-performance computing and big data analytics!\n",
    "These are application domains that the language was not necessarily designed for, but where performance is at least as important as programmer productivity.\n",
    "\n",
    "Luckily, there are work-arounds to make Python a lot more efficient.\n",
    "One example you may have worked with before is the [numpy] library.\n",
    "This is a Python library that helps to speed up computations on and decrease the in-memory size of multidimensional arrays and matrices.\n",
    "It does so by wrapping around a C implementation of these data structures and operations, unlocking the raw computational performance of natively compiled code for modern CPUs that have e.g. SIMD instructions.\n",
    "\n",
    "Numpy is mainly designed to operate on and store numeric data only. In big data analytics, we are often interested to work on tabular data structures that not only hold numbers, but also more complicated types, such as strings, nested lists, and many others.\n",
    "\n",
    "One project that can help us here is [Apache Arrow]. At the base of the project, there is a language-agnostic in-memory format specification for tabular data. This describes how tables can be laid out in memory in a way that's quite efficient for most applications and architectures (even for GPU and FPGA accelerators!).\n",
    "\n",
    "Let's first take a brief look at how to use some of the Python implementation of the Arrow library called `pyarrow`.\n",
    "\n",
    "[numpy]: https://numpy.org/\n",
    "[Apache Arrow]: https://arrow.apache.org/\n",
    "[productive]: https://xkcd.com/353/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sized-decision",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We first import the pyarrow library.\n",
    "import pyarrow as pa\n",
    "\n",
    "# Let's create something a bit bigger than our previous example S.\n",
    "# Let's make a sequence of dummy data that holds 10^8 64-bit integer values counting up from 0 to 10^8-1.\n",
    "# We'll call this sequence P for the *P*ython list representation of the sequence.\n",
    "P = list(range(int(10 ** 8)))\n",
    "\n",
    "# We can print the first couple of values (printing everything would probably crash the notebook)\n",
    "print(P[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "searching-inventory",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will now convert this Python list to an Arrow array which we will call A.\n",
    "A = pa.array(P)\n",
    "\n",
    "# Let's print the Arrow Array. We don't have to just print a slice, since Arrow is built for big data, \n",
    "# and understands we probably don't want to see all 10^8 values.\n",
    "print(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "heard-baking",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's sum up all values in the Python list, and then sum up all values in the Arrow array.\n",
    "# We will measure how long it takes (wall clock time).\n",
    "\n",
    "import time\n",
    "\n",
    "t0 = time.process_time()\n",
    "P_result = sum(P)\n",
    "t1 = time.process_time()\n",
    "print(\"Python: {:.4f} s. Result: {}\".format(t1 - t0, P_result))\n",
    "\n",
    "t0 = time.process_time()\n",
    "A_result = A.sum()\n",
    "t1 = time.process_time()\n",
    "print(\"Arrow : {:.4f} s. Result: {}\".format(t1 - t0, A_result))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vital-wilderness",
   "metadata": {},
   "source": [
    "The output should look something like:\n",
    "\n",
    "```\n",
    "Python: 0.2569 s. Result: 4999999950000000\n",
    "Arrow : 0.0305 s. Result: 4999999950000000\n",
    "```\n",
    "\n",
    "The result may be quite different depending on your computer, but if Arrow did its job, it should be faster to sum the Arrow array than summing the Python list. This is because the lay out of this particular data structure in Arrow (a sequence of 64-bit integers) looks more like what we showed in Table 1. This in-memory lay-out is much more suitable to be processed by modern CPUs. \n",
    "\n",
    "More technically, there are likely several components of your CPU that help make this faster in the Arrow case:\n",
    "- **Cache**: Loading data from main memory is done on a per-cacheline basis. Even if we load just one integer, we get a whole cacheline that typically holds multiple integers in our cache. Since in the Arrow format, integers are placed in the memory at consecutive addresses, whenever the first integer is loaded into the cache, a number of consecutive integers are also loaded into the cache, making access to them faster next time we load them, because we don't have to go all the way to main memory anymore. The CPU can thus benefit from what is called 'spatial locality' of our data structure and sum operation. For the Python case, the objects may be scattered around the memory, which kind of breaks the 'spatial locality' of the data. In other words, when we load one Python integer into the cache, it's less likely that we load another integer that we want to use into the cache with the same amount of work.\n",
    "- **Pre-fetchers**: Also because the integers are placed in the memory at consecutive addresses, a so called prefetcher can easily predict what data to load next. While the CPU is busy calculating the sum, the prefetcher can load the next cachelines into the cache already and in parallel to the busy CPU. Predicting what data to load next is very hard in the Python case, as the integers are potentially scattered around the memory, making it hard to correctly predict which data to fetch from the memory while the CPU is computing.\n",
    "- **SIMD**: Your CPU probably has SIMD instructions that sum up multiple (for AVX-512: 8) 64-bit integers at once, much faster than when using \"normal\" instructions that only sum up two integers at a time.\n",
    "\n",
    "An [interesting talk] by the Turing Award recipients in 2017 shows a similar example of how much performance there is to gain when we really attempt to utilize all the advances of modern processor architecture by being smart about our implementation within a specific application domain.\n",
    "\n",
    "###### The takeaway is ...\n",
    "\n",
    "... that in the design of many software languages, people have focused on productivity, which very often (but not always) comes at the cost of performance. If you are aware of this and if performance is an issue but you are not willing to implement your software in a language that is more performant, there are often various work-arounds such as numpy or Arrow that alleviate some of the bottlenecks (but will do so at the cost of having to write your code a bit differently).\n",
    "\n",
    "\n",
    "[interesting talk]: https://www.youtube.com/watch?v=3LVeEjsn8Ts&t=2243s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prescribed-sitting",
   "metadata": {},
   "source": [
    "## 3: Arrow RecordBatch\n",
    "\n",
    "The previous example is not very illustrative of the advantages of Arrow over, say, numpy, because numpy would be able to sum a sequence of integers just as well. However, as mentioned before, Arrow is good at tabular data structures with more complicated types - something numpy is less good at.\n",
    "\n",
    "The Arrow `Array` that we used, is actually typically used to represernt a column in a tabular data structure called a RecordBatch. Take a look at the following example, where we put a more complex tabular data structure into memory using the Arrow in-memory format using a RecordBatch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "liable-consequence",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# Let's consider a bunch of message records on a social-media platform.\n",
    "# Each message record has an id, a user, the contents, and some metadata.\n",
    "messages = [\n",
    "    {\n",
    "        'id': 42,\n",
    "        'user': 'Ronald Chevalier',\n",
    "        'contents': 'Hello Arrow! This is awesome!',\n",
    "        'meta': {\n",
    "            'date': datetime(2021, 10, 11, 12, 13, 14, 0),\n",
    "            'ref-id': None,\n",
    "            'liked-by': [\"Benjamin Purvis\", \"Tabatha Jenkins\"]\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        'id': 1337,\n",
    "        'user': 'Tabatha Jenkins',\n",
    "        'contents': \"IKR? Can't wait to use Fletcher!\",\n",
    "        'meta': {\n",
    "            'date': datetime(2021, 10, 11, 12, 13, 14, 0),\n",
    "            'ref-id': 42,\n",
    "            'liked-by': ['Lonnie Donaho']\n",
    "        }\n",
    "    },\n",
    "]\n",
    "\n",
    "# To get this data into Arrow, we use Pandas, which provides functions that do the conversion for us.\n",
    "# In a typical analytics pipeline, this data would come from storage and would be loaded directly as \n",
    "# an Arrow RecordBatch. Pandas also uses Arrow internally.\n",
    "import pandas as pd\n",
    "mdf = pd.DataFrame.from_records(messages, index='id')\n",
    "\n",
    "# Let's take a look at the data in a tabular form:\n",
    "display(mdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "specialized-sheet",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will now create an Arrow RecordBatch; a batch of records of the same type.\n",
    "batch = pa.RecordBatch.from_pandas(mdf)\n",
    "\n",
    "# Let's display some information about the batch:\n",
    "print(batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "contrary-clarity",
   "metadata": {},
   "source": [
    "In the output above, we can see that `batch` is a `pyarrow` RecordBatch.\n",
    "Arrow prints the name and type of each (nested) record field.\n",
    "This set of field names and their type is called the Arrow *schema*.\n",
    "The schema determines how to interpret the bytes that are stored in each column.\n",
    "In the next section, we'll continue to discover more of the internals of Arrow.\n",
    "\n",
    "Let us first perform some computations on the RecordBatch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "advisory-field",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this example, we will split the strings in the user column to obtain first and last name:\n",
    "\n",
    "# We can select the column as follows: batch.column('user')\n",
    "\n",
    "# Arrow also provides a library with compute functionality.\n",
    "# See: https://arrow.apache.org/docs/python/api/compute.html\n",
    "# In this case, we will use the split_pattern function to split the strings.\n",
    "split_names = pa.compute.split_pattern(batch.column('user'), pattern=' ')\n",
    "\n",
    "# Our result now holds a list of lists:\n",
    "print(split_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "challenging-digit",
   "metadata": {},
   "source": [
    "## Exercise 3.1: How much heavier did the earth get?\n",
    "\n",
    "In this exercise, we will load data from a file into an Apache Arrow RecordBatch, and perform a simple calculation on it.\n",
    "\n",
    "Suppose we are interested in learning how much mass the earth has gained from meteorites that crashed into it.\n",
    "We will use the [Meteorite Landings] dataset from NASA to calculate how much mass the earth has gained.\n",
    "This dataset is provided as the CSV file `meteorite.csv` in the folder of this Notebook.\n",
    "\n",
    "Your goal is to:\n",
    "\n",
    "1. Load the data as an Apache Arrow RecordBatch.\n",
    "\n",
    "Hints: you can use `pyarrow.csv.read_csv(...)` for this. You'll have to import csv from pyarrow seperately. This returns an Arrow Table, which works similar to a RecordBatch (but may be split up over multiple parts in the memory). If you want, can view the contents of the table using Pandas with: `display(table.to_pandas())`\n",
    "\n",
    "2. Sum meteorite mass up to find how much mass the earth has gained.\n",
    "\n",
    "Hints: you can use `pyarrow.compute.sum(...)` for this. This will return a `pyarrow.DoubleScalar` object.\n",
    "\n",
    "3. Print the result as a Python float.\n",
    "\n",
    "Hints: you can use `pyarrow.DoubleScalar.as_py()` for this. This converts the value from an Arrow representation of this value to a Python value.\n",
    "\n",
    "*Disclaimer: this exercise by no means represents a correct scientific view of the problem of calculating the difference in mass of the Earth over time.*\n",
    "\n",
    "[Meteorite Landings]: https://data.nasa.gov/Space-Science/Meteorite-Landings/ak9y-cwf9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beautiful-diary",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pyarrow import csv\n",
    "\n",
    "# Please keep the variable names on the left hand side intact.\n",
    "\n",
    "# 1. Load the data as an Apache Arrow RecordBatch. (Should not take more than one line)\n",
    "table = ...\n",
    "\n",
    "# 2. Sum meteorite mass up to find how much mass the earth has gained. (Should not take more than one line)\n",
    "total_mass = ...\n",
    "\n",
    "# 3. Print the result as a Python float. (Should not take more than one line)\n",
    "print(...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "supported-packing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Result check. If this assertion fails, something went wrong with your code!\n",
    "assert(total_mass.equals(pa.scalar(605281210.638)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "agricultural-plate",
   "metadata": {},
   "source": [
    "###### The takeaways is ...\n",
    "... that Apache Arrow can work with all kinds of tabular data, not just numbers, but also strings, structs, lists, and many others. It also provides various functions to perform computations on columns with these data types very efficiently."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "invisible-vermont",
   "metadata": {},
   "source": [
    "## 4: Columnar in-memory format\n",
    "\n",
    "When reading up on Arrow, you will often find the mention of it being a \"columnar\" in-memory format.\n",
    "What does that mean?\n",
    "\n",
    "Arrow stores tabular data in a column-oriented fashion (sometimes called struct-of-arrays).\n",
    "To explain what this means, let's first look at the usual/straightforward way of storing this data in memory, which would be called row-oriented (sometimes called array-of-structs).\n",
    "\n",
    "Consider the following struct in C:\n",
    "\n",
    "```C\n",
    "struct Person {\n",
    "   char name[4];    // People can only have very short names to make the table below small!\n",
    "   uint8_t salary;\n",
    "};\n",
    "```\n",
    "\n",
    "A C-array of this struct is laid out in memory as follows:\n",
    "\n",
    "| Address | Person / field / part |\n",
    "|---------|-----------------------|\n",
    "|       0 | Person 0 name character 0 |\n",
    "|       1 | Person 0 name character 1 |\n",
    "|       2 | Person 0 name character 2 |\n",
    "|       3 | Person 0 name character 3 |\n",
    "|       4 | Person 0 salary |\n",
    "|       5 | Person 1 name character 0 |\n",
    "|       6 | Person 1 name character 1 |\n",
    "|       7 | Person 1 name character 2 |\n",
    "|       8 | Person 1 name character 3 |\n",
    "|       9 | Person 1 salary |\n",
    "| ... | ... |\n",
    "\n",
    "**<center>Table 2: An example of an array of structures, or row-oriented in-memory format.</center>**\n",
    "\n",
    "*Technical disclaimer: this may differ depending on the compiler - another reason to use a language-agnostic in-memory format like Arrow!*\n",
    "\n",
    "Suppose we would now like to perform a vectorized sum of the salaries of each person to obtain the total salary some company has to pay to its employees.\n",
    "This is not immediately possible, because the name data is interleaved with the salary data. To do a vectorized sum, we need the salary data to be stored contiguously in the memory. \n",
    "The above example shows a row-oriented (array-of-structs) in-memory format for our data.\n",
    "\n",
    "We could also take another approach, suppose we have only two people:\n",
    "\n",
    "```C\n",
    "#define NUM_PEOPLE 2\n",
    "\n",
    "struct People {\n",
    "    uint8_t salaries[NUM_PEOPLE];\n",
    "    char name[4 * NUM_PEOPLE];\n",
    "}\n",
    "```\n",
    "\n",
    "We would end up with the following in-memory format:\n",
    "\n",
    "| Address | Person / field / part |\n",
    "|---------|-----------------------|\n",
    "|       0 | Person 0 salary |\n",
    "|       1 | Person 1 salary |\n",
    "|       2 | Person 0 name character 0 |\n",
    "|       3 | Person 0 name character 1 |\n",
    "|       4 | Person 0 name character 2 |\n",
    "|       5 | Person 0 name character 3 |\n",
    "|       6 | Person 1 name character 0 |\n",
    "|       7 | Person 1 name character 1 |\n",
    "|       8 | Person 1 name character 2 |\n",
    "|       9 | Person 1 name character 3 |\n",
    "\n",
    "**<center>Table 3: An example of a structure of arrays, or column-oriented in-memory format.</center>**\n",
    "\n",
    "Now, if we would like to sum all salaries, their values placed contiguously in the memory.\n",
    "This allows vector instructions to sum up multiple salaries at once.\n",
    "\n",
    "When looking at this data structure as a table, where each struct field of `struct Person` in the array of `struct Person` is considered a column, it should now become clear that we store columns seperately in the case of `struct People`, rather than interleaved as in the case of an array of `struct Person`.\n",
    "\n",
    "Back to Arrow. Arrow uses the second approach - each column is stored seperately from other columns to make sure the data in a column is stored contiguously. This way, we can perform all sorts of operations much faster (remember our previous little experiment!), especially those that work on one or a few columns, which is often the case in big data analytics.\n",
    "\n",
    "###### The takeaway is...\n",
    "... that tabular data structures can be stored in memory in a column-oriented fashion, such that all values in a column are in a contiguous piece of memory that allows operations to be performed on it faster."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "smoking-grammar",
   "metadata": {},
   "source": [
    "## 5: Variable-length data\n",
    "\n",
    "So far we've mainly looked at how fixed-size data is stored in memory, but what about variable-size data?\n",
    "The Arrow format is designed to store variable-sized data in such a way that it is easily accessible in parallel.\n",
    "\n",
    "Consider the an Arrow column with the strings \"abc\" and \"de\" on the first and second row.\n",
    "We could store them contiguously in memory in the C way:\n",
    "\n",
    "| Address | Character | Comment |\n",
    "|---------|-----|-|\n",
    "|       0 | 'a' | Start of the first string. |\n",
    "|       1 | 'b' | |\n",
    "|       2 | 'c' | |\n",
    "|       3 | '\\0' | String terminator character. | \n",
    "|       4 | 'd' Start of the second string. |\n",
    "|       5 | 'e' |\n",
    "|       6 | '\\0' | String terminator character. |\n",
    "\n",
    "Note C strings have a terminator character so we can know during run-time of our program where the end of the string is.\n",
    "\n",
    "Now suppose we would like to perform a transformation on these strings (e.g. we would like to calculate their hash).\n",
    "Imagine we have a ideal system that can run two software threads simultaneously without any overhead.\n",
    "To distribute the work over these two threads, we could give each thread one string to work on.\n",
    "For the first thread, we would tell it to start working from address 0, where the first string is located.\n",
    "However, during run-time, we would not know where the second string starts without first finding the first occurence of the terminator character `\\0`. This means we first have to scan the data for the terminator character, which incurs some overhead, in order to find where the second string starts. For this small example, this would be negligible, but when talking about datasets of terabytes in size, this will become very significant.\n",
    "\n",
    "To reduce the overhead associated with working with variable-length data in parallel, Arrow takes a different approach.\n",
    "So far we've worked with Arrow arrays, and looked at a few that, in terms of their in-memory layout, are identical to arrays in C.\n",
    "However, Arrow arrays are only a logical view of the combination of various Arrow *buffers* where the Arrow array type determines how to interpret the buffers.\n",
    "Arrays can also be nested, although we will not go into details in this lab.\n",
    "\n",
    "To understand the previous paragraph, let's look at an example of the same data stored using Arrow.\n",
    "\n",
    "One part will be stored in what is called the \"values\" buffer:\n",
    "\n",
    "| Address | Character | Comment |\n",
    "|---------|-----|-|\n",
    "|       0 | 'a' | Start of the first string. |\n",
    "|       1 | 'b' | |\n",
    "|       2 | 'c' | |\n",
    "|       3 | 'd' | Start of the second string. |\n",
    "|       4 | 'e' | |\n",
    "|     ... | ... | |\n",
    "\n",
    "Another part will be stored in what is called the \"offsets\" buffer:\n",
    "\n",
    "| Address | Offset | Comment |\n",
    "|---------|--------|---------|\n",
    "|       0 |      0 | Offset into the \"values\" buffer for the first string. |\n",
    "|       4 |      3 | Offset into the \"values\" buffer for the second string. |\n",
    "|       8 |      5 | Offset of the end+1 of the \"values\" buffer. |\n",
    "|     ... |    ... | |\n",
    "\n",
    "Here we have two Arrow buffers, which are C-like arrays that, when combined, form an Arrow `StringArray`.\n",
    "The offsets buffer holds offsets into the values array, that point to where strings start.\n",
    "Note that offsets are (by default) 32-bit integers, so they take up four bytes worth of address space.\n",
    "This way, we don't have to traverse all characters to find the terminator character to know where a string starts, so it's easy and fast to slice the `StringArray` up into multiple parts so we can process it in parallel.\n",
    "\n",
    "Let's take a look at RecordBatch with the messages again to confirm a `StringArray` indeed works as such."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rough-dollar",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We take the 'user' column from our RecordBatch\n",
    "string_array = batch.column('user')\n",
    "\n",
    "# After running this, you will see this is a pyarrow StringArray, and it holds two strings.\n",
    "display(string_array)\n",
    "\n",
    "# We can check out the underlying Arrow buffers. There are three.\n",
    "# At the first index, there is `None`, meaning there is no buffer.\n",
    "# This is reserved for the \"validity buffer\", which we will explain later.\n",
    "print(\"Validity buffer (unused for this example):\")\n",
    "display(string_array.buffers()[0])\n",
    "\n",
    "# At the second index, there is the offsets buffer. \n",
    "# We will pretend it is an Arrow int32 array so we can view it.\n",
    "print(\"Offsets buffer contents:\")\n",
    "display(pa.Int32Array.from_buffers(pa.int32(), 3, [None, string_array.buffers()[1]]))\n",
    "\n",
    "# At the third index, there is the values buffer.\n",
    "print(\"Values buffer contents:\")\n",
    "display(['{:2d} : {}'.format(i,chr(x)) for i,x in enumerate(string_array.buffers()[2].to_pybytes())])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "surgical-comment",
   "metadata": {},
   "source": [
    "From the above example, we can see how the offsets and values buffers together represent the column of strings 'user' from our message dataset example in section 3. \n",
    "\n",
    "When variable-sized data types are nested, such as lists of lists, there will be two offset buffers, the first one pointing into the second one, and the second one pointing into the values buffer.\n",
    "\n",
    "###### The takeaway is ...\n",
    "\n",
    "... that Arrow arrays can consist of multiple buffers, that work together to represent columns of all sorts of complex and variable-size data types. Arrow deals with variable-size data using offset buffers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "liable-carpet",
   "metadata": {},
   "source": [
    "## Exercise answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "existing-darkness",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer 3.1\n",
    "table = pa.csv.read_csv(\"meteorites.csv\")\n",
    "total_mass = pa.compute.sum(table.column('mass (g)'))\n",
    "print(total_mass.as_py())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
